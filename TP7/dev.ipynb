{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "roi_defined = False\n",
    " \n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked, \n",
    "\t# record the starting ROI coordinates \n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)  \n",
    "\t\troi_defined = True\n",
    "\n",
    "cap = cv2.VideoCapture('video\\Antoine_Mug.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    " \n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    " \n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored \n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "    if ret == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        hsvDisp = hsv\n",
    "        hsvDisp[:,:,1] = 255\n",
    "        hsvDisp[:,:,2] = 255\n",
    "\n",
    "        hueDisp = cv2.cvtColor(hsvDisp, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "\t\t# Backproject the model histogram roi_hist onto the \n",
    "\t\t# current image hsv, i.e. dst(x,y) = roi_hist(hsv(0,x,y))\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "\n",
    "        # apply meanshift to dst to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw a blue rectangle on the current image\n",
    "        r,c,h,w = track_window\n",
    "        frame_tracked = cv2.rectangle(frame, (r,c), (r+h,c+w), (255,0,0) ,2)\n",
    "\n",
    "        #windows to display\n",
    "        cv2.imshow('Sequence',frame_tracked)\n",
    "        cv2.imshow('Hue', hueDisp)\n",
    "        cv2.imshow('Retroprojection', dst)\n",
    "\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('Frame_%04d.png'%cpt,frame_tracked)\n",
    "            cv2.imwrite('Frame_hue_%04d.png'%cpt,hueDisp)\n",
    "            cv2.imwrite('Frame_repro_%04d.png'%cpt,dst)\n",
    "        cpt += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from skimage import filters\n",
    "\n",
    "roi_defined = False\n",
    "threshold = 20\n",
    "\n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked,\n",
    "\t# record the starting ROI coordinates\n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)\n",
    "\t\troi_defined = True\n",
    "\n",
    "def calculate_gradient_orientation(frame, threshold):\n",
    "    \"\"\"\n",
    "    This function calculates the gradient orientation and gradient magnitude \n",
    "    for a given grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    - frame (ndarray): Input grayscale image\n",
    "    - threshold (float): Minimum gradient magnitude to consider a pixel for further processing\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Tuple containing gradient magnitude, gradient orientation, valid orientation pixels, \n",
    "             invalid orientation pixels and valid index.\n",
    "    \"\"\"\n",
    "    # Calculate gradient magnitude using gradient of image\n",
    "    gradient_x, gradient_y = np.gradient(frame[:, :, 2])\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "    # Calculate gradient orientation using arctan2\n",
    "    gradient_orientation = np.arctan2(gradient_x, gradient_y)\n",
    "\n",
    "\n",
    "    # Identify invalid pixels with gradient magnitude below the threshold\n",
    "    invalid_index = np.where(gradient_magnitude < threshold)\n",
    "    valid_index = np.where(gradient_magnitude > threshold)\n",
    "\n",
    "    # Normalize orientation values and convert to uint8\n",
    "    valid_orientation = cv2.cvtColor(np.float32(gradient_orientation), cv2.COLOR_GRAY2BGR)\n",
    "    valid_orientation = cv2.normalize(valid_orientation, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    valid_orientation = np.uint8(valid_orientation)\n",
    "    valid_orientation[invalid_index[0], invalid_index[1], :] = [0, 0, 255]\n",
    "\n",
    "    gradient_magnitude = (gradient_magnitude-gradient_magnitude.min())/(float)(gradient_magnitude.max() - gradient_magnitude.min())\n",
    "\n",
    "    return gradient_magnitude, gradient_orientation, valid_orientation, invalid_index, valid_index\n",
    "\n",
    "def calcHoughTransform(accumulator, angle, radii_table, valid_indices):\n",
    "    \"\"\"\n",
    "    Calculate the Hough transform given the orientation and radius information.\n",
    "    \n",
    "    Parameters:\n",
    "    - accumulator: 2D numpy array representing the accumulator space\n",
    "    - angle: 2D numpy array representing the gradient orientation\n",
    "    - radii_table: dictionary representing the possible radii values\n",
    "    - valid_indices: tuple of two 1D numpy arrays representing the x and y indices of valid pixels\n",
    "\n",
    "    Returns:\n",
    "    - accumulator: updated accumulator space\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert orientation to degrees and round to nearest integer\n",
    "    angle_degrees = np.round(np.rad2deg(angle)).astype(np.int32)\n",
    "    \n",
    "    # Create a kernel for each radius value\n",
    "    for radius, values in radii_table.items():\n",
    "        for value in values:\n",
    "            x = valid_indices[1] + value[0]\n",
    "            y = valid_indices[0] + value[1]\n",
    "            \n",
    "            # Check if the indices are within bounds\n",
    "            mask = np.logical_and(\n",
    "                np.logical_and(x >= 0, x < accumulator.shape[1]),\n",
    "                np.logical_and(y >= 0, y < accumulator.shape[0]),\n",
    "            )\n",
    "            \n",
    "            # Increment the accumulator for the corresponding angle and radius\n",
    "            accumulator[y[mask], x[mask]] += 1\n",
    "    \n",
    "    return accumulator\n",
    "\n",
    "cap = cv2.VideoCapture('video\\VOT-Ball.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    "\n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse :\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored\n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "\n",
    "# Create the R-table to store the distances of valid gradient pixels based on their orientation\n",
    "r_table = defaultdict(list)\n",
    "\n",
    "# Calculate the gradient magnitude and orientation\n",
    "gradient, orientation, _, _, valid_indices = calculate_gradient_orientation(hsv_roi, threshold)\n",
    "\n",
    "# Find the center of the ROI\n",
    "roi_center = np.array([int(r + (h//2)), int(c + (w//2))])\n",
    "\n",
    "# Convert orientation values from radians to degrees\n",
    "orientation = np.round(orientation * 180 / np.pi).astype(np.int32)\n",
    "\n",
    "# Populate the R-table\n",
    "for px, py in zip(valid_indices[0], valid_indices[1]):\n",
    "    # Calculate the distance from the center of the ROI for each valid gradient pixel\n",
    "    distance = roi_center - np.array([py + r, px + c])\n",
    "    # Store the distance in the R-table based on the orientation of the pixel\n",
    "    r_table[orientation[px, py]].append(distance)\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "\tret ,frame = cap.read()\n",
    "\tif ret == True:\n",
    "\t\tframe_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\t\t# Calculate gradient magnitude and orientation\n",
    "\t\tgradient, orientation, ori, _, valid_indices = calculate_gradient_orientation(frame_hsv, threshold)\n",
    "\n",
    "\t\t# Initialize Hough Transform\n",
    "\t\though_transform = np.zeros(orientation.shape)\n",
    "\n",
    "\t\t# Calculate Hough Transform\n",
    "\t\though_transform = calcHoughTransform(hough_transform, orientation, r_table, valid_indices)\n",
    "\n",
    "\t\t# Find the maximum value of the Hough Transform and its index\n",
    "\t\tcy, cx = np.unravel_index(np.argmax(hough_transform), hough_transform.shape)\n",
    "\t\tr, c = max(cx - (h // 2), 0), max(cy - (w // 2), 0)\n",
    "\n",
    "\t\t# Draw a blue rectangle on the frame\n",
    "\t\tframe_tracked = cv2.rectangle(frame, (r, c), (r + h, c + w), (255, 0, 0), 2)\n",
    "\n",
    "\t\t# Normalize Hough Transform\n",
    "\t\though_transform = (hough_transform-hough_transform.min())/(float)(hough_transform.max() - hough_transform.min())\n",
    "\n",
    "\t\t#Plotting all images\n",
    "\t\tcv2.imshow('Sequence', frame_tracked)\n",
    "\t\tcv2.imshow('Valid orientation', ori)\n",
    "\t\tcv2.imshow(\"Orientation / argument\", orientation)\n",
    "\t\tcv2.imshow(\"Gradient magnitude\", gradient)\n",
    "\t\tcv2.imshow(\"Transformee Hough\", hough_transform)\n",
    "\n",
    "\t\tk = cv2.waitKey(60) & 0xff\n",
    "\t\tif k == 27:\n",
    "\t\t\t\tbreak\n",
    "\t\telif k == ord('s'):\n",
    "\t\t\t\tcv2.imwrite('Q4_Frame_%04d.png'%cpt,frame_tracked)\n",
    "\t\t\t\tcv2.imwrite('Q4_Frame_Hough_%04d.png'%cpt,hough_transform)\n",
    "\t\t\t\tcv2.imwrite('Q4_Frame_Ori_%04d.png'%cpt,ori)\n",
    "\t\tcpt += 1\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough + Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "roi_defined = False\n",
    "threshold = 20\n",
    "\n",
    "def define_ROI(event, x, y, flags, param):\n",
    "\tglobal r,c,w,h,roi_defined\n",
    "\t# if the left mouse button was clicked,\n",
    "\t# record the starting ROI coordinates\n",
    "\tif event == cv2.EVENT_LBUTTONDOWN:\n",
    "\t\tr, c = x, y\n",
    "\t\troi_defined = False\n",
    "\t# if the left mouse button was released,\n",
    "\t# record the ROI coordinates and dimensions\n",
    "\telif event == cv2.EVENT_LBUTTONUP:\n",
    "\t\tr2, c2 = x, y\n",
    "\t\th = abs(r2-r)\n",
    "\t\tw = abs(c2-c)\n",
    "\t\tr = min(r,r2)\n",
    "\t\tc = min(c,c2)\n",
    "\t\troi_defined = True\n",
    "\n",
    "def calculate_gradient_orientation(frame, threshold):\n",
    "    \"\"\"\n",
    "    This function calculates the gradient orientation and gradient magnitude \n",
    "    for a given grayscale image.\n",
    "\n",
    "    Parameters:\n",
    "    - frame (ndarray): Input grayscale image\n",
    "    - threshold (float): Minimum gradient magnitude to consider a pixel for further processing\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Tuple containing gradient magnitude, gradient orientation, valid orientation pixels, \n",
    "             invalid orientation pixels and valid index.\n",
    "    \"\"\"\n",
    "    # Calculate gradient magnitude using gradient of image\n",
    "    gradient_x, gradient_y = np.gradient(frame[:, :, 2])\n",
    "    gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "\n",
    "    # Calculate gradient orientation using arctan2\n",
    "    gradient_orientation = np.arctan2(gradient_x, gradient_y)\n",
    "\n",
    "\n",
    "    # Identify invalid pixels with gradient magnitude below the threshold\n",
    "    invalid_index = np.where(gradient_magnitude < threshold)\n",
    "    valid_index = np.where(gradient_magnitude > threshold)\n",
    "\n",
    "    # Normalize orientation values and convert to uint8\n",
    "    valid_orientation = cv2.cvtColor(np.float32(gradient_orientation), cv2.COLOR_GRAY2BGR)\n",
    "    valid_orientation = cv2.normalize(valid_orientation, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    valid_orientation = np.uint8(valid_orientation)\n",
    "    valid_orientation[invalid_index[0], invalid_index[1], :] = [0, 0, 255]\n",
    "\n",
    "    gradient_magnitude = (gradient_magnitude-gradient_magnitude.min())/(float)(gradient_magnitude.max() - gradient_magnitude.min())\n",
    "\n",
    "    return gradient_magnitude, gradient_orientation, valid_orientation, invalid_index, valid_index\n",
    "\n",
    "def calcHoughTransform(accumulator, angle, radii_table, valid_indices):\n",
    "    \"\"\"\n",
    "    Calculate the Hough transform given the orientation and radius information.\n",
    "    \n",
    "    Parameters:\n",
    "    - accumulator: 2D numpy array representing the accumulator space\n",
    "    - angle: 2D numpy array representing the gradient orientation\n",
    "    - radii_table: dictionary representing the possible radii values\n",
    "    - valid_indices: tuple of two 1D numpy arrays representing the x and y indices of valid pixels\n",
    "\n",
    "    Returns:\n",
    "    - accumulator: updated accumulator space\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert orientation to degrees and round to nearest integer\n",
    "    angle_degrees = np.round(np.rad2deg(angle)).astype(np.int32)\n",
    "    \n",
    "    # Create a kernel for each radius value\n",
    "    for radius, values in radii_table.items():\n",
    "        for value in values:\n",
    "            x = valid_indices[1] + value[0]\n",
    "            y = valid_indices[0] + value[1]\n",
    "            \n",
    "            # Check if the indices are within bounds\n",
    "            mask = np.logical_and(\n",
    "                np.logical_and(x >= 0, x < accumulator.shape[1]),\n",
    "                np.logical_and(y >= 0, y < accumulator.shape[0]),\n",
    "            )\n",
    "            \n",
    "            # Increment the accumulator for the corresponding angle and radius\n",
    "            accumulator[y[mask], x[mask]] += 1\n",
    "    \n",
    "    return accumulator\n",
    "\n",
    "cap = cv2.VideoCapture('video\\VOT-Ball.mp4')\n",
    "\n",
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# load the image, clone it, and setup the mouse callback function\n",
    "clone = frame.copy()\n",
    "cv2.namedWindow(\"First image\")\n",
    "cv2.setMouseCallback(\"First image\", define_ROI)\n",
    "\n",
    "# keep looping until the 'q' key is pressed\n",
    "while True:\n",
    "\t# display the image and wait for a keypress\n",
    "\tcv2.imshow(\"First image\", frame)\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t# if the ROI is defined, draw it!\n",
    "\tif (roi_defined):\n",
    "\t\t# draw a green rectangle around the region of interest\n",
    "\t\tcv2.rectangle(frame, (r,c), (r+h,c+w), (0, 255, 0), 2)\n",
    "\t# else reset the image...\n",
    "\telse:\n",
    "\t\tframe = clone.copy()\n",
    "\t# if the 'q' key is pressed, break from the loop\n",
    "\tif key == ord(\"q\"):\n",
    "\t\tbreak\n",
    "\n",
    "track_window = (r,c,h,w)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[c:c+w, r:r+h]\n",
    "# conversion to Hue-Saturation-Value space\n",
    "# 0 < H < 180 ; 0 < S < 255 ; 0 < V < 255\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "# computation mask of the histogram:\n",
    "# Pixels with S<30, V<20 or V>235 are ignored\n",
    "mask = cv2.inRange(hsv_roi, np.array((0.,30.,20.)), np.array((180.,255.,235.)))\n",
    "# Marginal histogram of the Hue component\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "# Histogram values are normalised to [0,255]\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria: either 10 iterations,\n",
    "# or move by less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "\n",
    "# Create the R-table to store the distances of valid gradient pixels based on their orientation\n",
    "r_table = defaultdict(list)\n",
    "\n",
    "# Calculate the gradient magnitude and orientation\n",
    "gradient, orientation, _, _, valid_indices = calculate_gradient_orientation(hsv_roi, threshold)\n",
    "\n",
    "# Find the center of the ROI\n",
    "roi_center = np.array([int(r + (h//2)), int(c + (w//2))])\n",
    "\n",
    "# Convert orientation values from radians to degrees\n",
    "orientation = np.round(orientation * 180 / np.pi).astype(np.int32)\n",
    "\n",
    "# Populate the R-table\n",
    "for px, py in zip(valid_indices[0], valid_indices[1]):\n",
    "    # Calculate the distance from the center of the ROI for each valid gradient pixel\n",
    "    distance = roi_center - np.array([py + r, px + c])\n",
    "    # Store the distance in the R-table based on the orientation of the pixel\n",
    "    r_table[orientation[px, py]].append(distance)\n",
    "\n",
    "cpt = 1\n",
    "while(1):\n",
    "\tret ,frame = cap.read()\n",
    "\tif ret == True:\n",
    "\n",
    "\t\tframe_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\t\t# Calculate gradient magnitude and orientation\n",
    "\t\tgradient, orientation, ori, _, valid_indices = calculate_gradient_orientation(frame_hsv, threshold)\n",
    "\n",
    "\t\t# Initialize Hough Transform\n",
    "\t\though_transform = np.zeros(orientation.shape)\n",
    "\n",
    "\t\t# Calculate Hough Transform\n",
    "\t\though_transform = calcHoughTransform(hough_transform, orientation, r_table, valid_indices)\n",
    "\n",
    "\n",
    "\t\t#mean shift\n",
    "\t\tret, track_window = cv2.meanShift(hough_transform, track_window, term_crit)\n",
    "\t\tr,c,h,w = track_window\n",
    "\n",
    "\t\t# Draw a blue rectangle on the current image and normalize Hough\n",
    "\t\tframe_tracked = cv2.rectangle(frame, (r, c), (r + h, c + w), (255, 0, 0), 2)\n",
    "\t\t# Normalize Hough Transform\n",
    "\t\though_transform = (hough_transform-hough_transform.min())/(float)(hough_transform.max() - hough_transform.min())\n",
    "\n",
    "\t\t#Plotting all images\n",
    "\t\tcv2.imshow('Sequence', frame_tracked)\n",
    "\t\tcv2.imshow('Orientation', ori)\n",
    "\t\tcv2.imshow(\"Transformee Hough\", hough_transform)\n",
    "\n",
    "\t\tk = cv2.waitKey(60) & 0xff\n",
    "\t\tif k == 27:\n",
    "\t\t\t\tbreak\n",
    "\t\telif k == ord('s'):\n",
    "\t\t\t\tcv2.imwrite('./images/Q5_Frame_%04d.png'%cpt,frame_tracked)\n",
    "\t\t\t\tcv2.imwrite('./images/Q5_Frame_tHough_%04d.png'%cpt,hough_transform)\n",
    "\t\t\t\tcv2.imwrite('./images/Q5_Frame_Ori_%04d.png'%cpt,ori)\n",
    "\t\tcpt += 1\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16f5b46f222e2a3e8d4adbf7141cae37b71ed37616e60735fa5d1164a1bc3ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
